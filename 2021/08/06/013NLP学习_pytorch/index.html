<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>关于NLP的学习 | Ethanyi's Blog</title><meta name="keywords" content="深度学习"><meta name="author" content="ethanyi"><meta name="copyright" content="ethanyi"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="深度学习的概念深度学习从广义上来讲就是程序可以自己学习自己的意思。是指一个已经写好的代码程序经过大量的数据使得自身得到了发展 总共有三个部分的特征： 一、反向传播算法 二、特征提取能力 三、端到端之间的学习方法 学习pytorch特点中间有三个特点： 1、完全符合python编程（tensorflow就不行，是在python语法和TensorFlow自己有些格式之间转换） 2、方便的张量（tens">
<meta property="og:type" content="article">
<meta property="og:title" content="关于NLP的学习">
<meta property="og:url" content="https://thanyi.github.io/2021/08/06/013NLP%E5%AD%A6%E4%B9%A0_pytorch/index.html">
<meta property="og:site_name" content="Ethanyi&#39;s Blog">
<meta property="og:description" content="深度学习的概念深度学习从广义上来讲就是程序可以自己学习自己的意思。是指一个已经写好的代码程序经过大量的数据使得自身得到了发展 总共有三个部分的特征： 一、反向传播算法 二、特征提取能力 三、端到端之间的学习方法 学习pytorch特点中间有三个特点： 1、完全符合python编程（tensorflow就不行，是在python语法和TensorFlow自己有些格式之间转换） 2、方便的张量（tens">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/thanyi/image/20210814164731.png">
<meta property="article:published_time" content="2021-08-06T15:37:53.000Z">
<meta property="article:modified_time" content="2021-09-14T01:37:20.392Z">
<meta property="article:author" content="ethanyi">
<meta property="article:tag" content="深度学习">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/thanyi/image/20210814164731.png"><link rel="shortcut icon" href="/img/avatar.jpeg"><link rel="canonical" href="https://thanyi.github.io/2021/08/06/013NLP%E5%AD%A6%E4%B9%A0_pytorch/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: true
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2021-09-14 09:37:20'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    })(window)</script><link rel="stylesheet" href="/css/my_css.css"><meta name="generator" content="Hexo 5.4.0"><link rel="alternate" href="/atom.xml" title="Ethanyi's Blog" type="application/atom+xml">
</head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" src="/img/avatar.jpeg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">26</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">22</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">19</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa fa-list"></i><span> 生活</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/artitalk/"><i class="fa-fw fa fa-comments"></i><span> 说说</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://cdn.jsdelivr.net/gh/thanyi/image/20210814164731.png')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Ethanyi's Blog</a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa fa-list"></i><span> 生活</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/artitalk/"><i class="fa-fw fa fa-comments"></i><span> 说说</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">关于NLP的学习</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2021-08-06T15:37:53.000Z" title="发表于 2021-08-06 23:37:53">2021-08-06</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2021-09-14T01:37:20.392Z" title="更新于 2021-09-14 09:37:20">2021-09-14</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E5%AD%A6%E4%B9%A0/">学习</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">1.7k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>5分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="深度学习的概念"><a href="#深度学习的概念" class="headerlink" title="深度学习的概念"></a>深度学习的概念</h1><p>深度学习从广义上来讲就是程序可以自己学习自己的意思。是指一个已经写好的代码程序经过大量的数据使得自身得到了发展</p>
<p>总共有三个部分的特征：</p>
<p>一、反向传播算法</p>
<p>二、特征提取能力</p>
<p>三、端到端之间的学习方法</p>
<h1 id="学习pytorch"><a href="#学习pytorch" class="headerlink" title="学习pytorch"></a>学习pytorch</h1><h2 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h2><p>中间有三个特点：</p>
<p>1、完全符合python编程（tensorflow就不行，是在python语法和TensorFlow自己有些格式之间转换）</p>
<p>2、方便的张量（tensor）计算 –&gt;可以将变量加载到GPU（图形处理器）上</p>
<p>3、对动态计算图的支持 —-&gt;动态计算图，是pytorch的特有特性，是可以用来表示反向传播算法的一种图示</p>
<img src="https://cdn.jsdelivr.net/gh/thanyi/image/20210806235217.png">

<h2 id="使用pytorch进行深度学习的步骤"><a href="#使用pytorch进行深度学习的步骤" class="headerlink" title="使用pytorch进行深度学习的步骤"></a>使用pytorch进行深度学习的步骤</h2><h3 id="构建神经网络模型"><a href="#构建神经网络模型" class="headerlink" title="构建神经网络模型"></a>构建神经网络模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">neu = torch.nn.Sequential(</span><br><span class="line">	torch.nn.Linear(input_size,hidden_size), <span class="comment">#输入层到隐含层之间的线性运算</span></span><br><span class="line">	torch.nn.Sigmoid(),		<span class="comment">#作用在对隐含层的每一个神经元</span></span><br><span class="line">	torch.nn.Linear(hidden_size,output_size),  <span class="comment">#从隐含层到输出层的线性运算</span></span><br><span class="line">)	</span><br></pre></td></tr></table></figure>

<p>这个格式的参数输入可以将所有神经网络的参数储存在neu.parameters中</p>
<p><strong>其中输入层的每一个神经元都是多维向量的一个维度</strong></p>
<p><img src="https://cdn.jsdelivr.net/gh/thanyi/image/20210807204929.png"></p>
<h3 id="建立损失函数和优化器"><a href="#建立损失函数和优化器" class="headerlink" title="建立损失函数和优化器"></a>建立损失函数和优化器</h3><h4 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h4><p>用来评价模型的<strong>预测值</strong>和<strong>真实值</strong>不一样的程度，损失函数越好，通常模型的性能越好。不同的模型用的损失函数一般也不一样。</p>
<p>pytorch中的损失函数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cost = torch.nn.MSELoss()</span><br></pre></td></tr></table></figure>

<p>torch.nn.MSELoss() &lt;——–&gt;  torch.mean((y-y*)^2)</p>
<p>意识是预测值和真实值差的平方的平均值</p>
<p>cost是函数指针，指向这个mseloss函数</p>
<h4 id="优化器"><a href="#优化器" class="headerlink" title="优化器"></a>优化器</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">optimizer = torch.optim.SGD(neu.parameters(),lr=<span class="number">0.01</span>)</span><br></pre></td></tr></table></figure>

<p>neu.parameters是定义好的神经网络中的所有等待被优化的所有参数的集合</p>
<p>lr是学习效率参数</p>
<h3 id="对神经网络进行分批次训练"><a href="#对神经网络进行分批次训练" class="headerlink" title="对神经网络进行分批次训练"></a>对神经网络进行分批次训练</h3><h1 id="预处理"><a href="#预处理" class="headerlink" title="预处理"></a>预处理</h1><h2 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h2><p>类型变量：数值的大小没有特殊的含义。比如说预测当地此时具有的共享单车数的时候的”星期几”这个变量。与之相对的是–特征变量(特征属性，在一个表中的特征列)</p>
<h2 id="预处理手段"><a href="#预处理手段" class="headerlink" title="预处理手段"></a>预处理手段</h2><p>一、对类型变量进行类型编码，比如one-hot编码</p>
<p>二、数据变量标准化(归一化)，对数值变量进行统一化运算，使其更加方便运算。(比如对数据减去均值再除以方差)</p>
<p> <img src="https://cdn.jsdelivr.net/gh/thanyi/image/20210807203214.png"></p>
<p>三、分批训练，将其分类为训练集、测试集。还有将其切分成小批，一批一批地进入神经网络，每一批训练网络一次</p>
<h1 id="实例：关于分类相关的深度学习"><a href="#实例：关于分类相关的深度学习" class="headerlink" title="实例：关于分类相关的深度学习"></a>实例：关于分类相关的深度学习</h1><p>例子：文本分类的问题</p>
<h2 id="文本向量化"><a href="#文本向量化" class="headerlink" title="文本向量化"></a>文本向量化</h2><p>文本向量化是将一个不固定长度的文本变成一个固定长度的向量</p>
<p>所采用的技术就是<strong>词袋模型</strong></p>
<p><strong>词袋模型</strong>是指将一段文本的所有词视为一个装满文本的大袋子，忽略单词之间的顺序，只看频率，并且将这个大袋子中的单词全部变成向量，有多少个单词就是多少维的向量</p>
<p>举例：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">我 爱 北京 天安门</span><br><span class="line">每个 人 都有 一个 爱 的 人</span><br></pre></td></tr></table></figure>

<p>那么我们对应的单词表就是</p>
<p>{我，爱，北京，天安门，每个，人，都有，一个，的}—–&gt; 九维向量</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">我 爱 北京 天安门</span><br><span class="line">&#123;1&#x2F;4，1&#x2F;4，1&#x2F;4，1&#x2F;4，0，0，0，0，0&#125;  #向量表示</span><br><span class="line">每个 人 都有 一个 爱 的 人</span><br><span class="line">&#123;0，1&#x2F;7，0，0，1&#x2F;7，2&#x2F;7，1&#x2F;7，1&#x2F;7，1&#x2F;7&#125; #向量表示</span><br></pre></td></tr></table></figure>

<h2 id="构造分类器"><a href="#构造分类器" class="headerlink" title="构造分类器"></a>构造分类器</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">model &#x3D; nn.Sequential(</span><br><span class="line">	nn.Linear(input_size,hidden_size),</span><br><span class="line">	nn.ReLU(), #在计算的速度上更快，并且有利于梯度信息的传递，在一定程度上避免了梯度爆炸的问题</span><br><span class="line">	nn.Linear(hidden_size,2), #2是因为这个就是个分类，我们假设分成2类</span><br><span class="line">	nn.LogSoftmax(dim&#x3D;), #用于解决分类问题的分类输出层计算</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<h1 id="pytorch的工具"><a href="#pytorch的工具" class="headerlink" title="pytorch的工具"></a>pytorch的工具</h1><h2 id="TensorBoard的使用"><a href="#TensorBoard的使用" class="headerlink" title="TensorBoard的使用"></a>TensorBoard的使用</h2><p>TensorBoard是一个对于我们想要展示的图片的展示平台</p>
<p>在存在pytorch的环境里面的终端使用命令</p>
<figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensorboard --logdir logs(这个是你规定的文件夹名) --port 你的端口</span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/thanyi/image/20210913155329.png"></p>
<h3 id="语法"><a href="#语法" class="headerlink" title="语法"></a>语法</h3><p>首先需要导入包</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br></pre></td></tr></table></figure>

<p>对SummaryWriter生成对象，使用PIL来将路径中的图片来变成对象</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">writer &#x3D; SummaryWriter(&#39;logs&#39;)</span><br><span class="line">img_path &#x3D; &#39;data&#x2F;train&#x2F;ants_img&#x2F;5650366_e22b7e1065.jpg&#39;</span><br><span class="line">image_PIL &#x3D; Image.open(img_path)</span><br></pre></td></tr></table></figure>

<p>使用numpy把PIL的对象变成numpy的数组，再导入进Writer对象，（writer中只接受numpy数组或者其他的参数，反正PIL的不行）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">img_array = np.array(image_PIL)</span><br><span class="line">writer.add_image(<span class="string">&#x27;train&#x27;</span>,img_array,<span class="number">1</span>,dataformats=<span class="string">&#x27;HWC&#x27;</span>) </span><br><span class="line">//参数分别是名字，数组（数据），<span class="number">1</span>是指step，每次变的话可要在tensorboard上有很多步骤，hwc是一种格式问题</span><br></pre></td></tr></table></figure>

<p><img src="/2021/08/06/013NLP%E5%AD%A6%E4%B9%A0_pytorch/Users\ethanyi\AppData\Roaming\Typora\typora-user-images\image-20210913162314922.png" alt="image-20210913162314922"></p>
<p>或者我如果想要添加数组，做图像</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line">    writer.add_scalar(<span class="string">&quot;y=5x&quot;</span>,<span class="number">3</span>*i,i)</span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/thanyi/image/20210913162217.png"></p>
<p>最后关闭函数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">writer.close()</span><br></pre></td></tr></table></figure>

<h2 id="transform使用"><a href="#transform使用" class="headerlink" title="transform使用"></a>transform使用</h2><p>transform是pytorch中的一个工具箱，里面有很多的功能工具</p>
<p>一般来说是用来对图片做一些处理，输入一个图片，输出一个结果</p>
<h3 id="用法（以totensor-为例）"><a href="#用法（以totensor-为例）" class="headerlink" title="用法（以totensor()为例）"></a>用法（以totensor()为例）</h3><p>首先弄一个对象，transform的对象，再输入一个图片类型 就可以对其操作，进行输出</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">from torch.utils.tensorboard import SummaryWriter</span><br><span class="line">import cv2</span><br><span class="line">from torchvision.transforms import transforms</span><br><span class="line"></span><br><span class="line">img_path&#x3D;&#39;data&#x2F;train&#x2F;ants_img&#x2F;5650366_e22b7e1065.jpg&#39;</span><br><span class="line">writer &#x3D; SummaryWriter(&#39;logs&#39;)</span><br><span class="line">img &#x3D; cv2.imread(img_path)</span><br><span class="line"></span><br><span class="line">tensor_trans &#x3D; transforms.ToTensor()</span><br><span class="line">trans_img &#x3D; tensor_trans(img)</span><br><span class="line"></span><br><span class="line">writer.add_image(&#39;test1&#39;, trans_img)</span><br><span class="line"></span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure>

<p>还有很多其他的，compose()主要是合并，resize()是改变图片大小</p>
<p>就懒得讲了</p>
<h1 id="pytorch数据集的读取"><a href="#pytorch数据集的读取" class="headerlink" title="pytorch数据集的读取"></a>pytorch数据集的读取</h1><h2 id="torchvision中的datasets和DataLoader"><a href="#torchvision中的datasets和DataLoader" class="headerlink" title="torchvision中的datasets和DataLoader"></a>torchvision中的datasets和DataLoader</h2><p>这是一个图片的数据集的模块，有关图片的数据的读取利用都是用这个模块</p>
<h3 id="dataset用法"><a href="#dataset用法" class="headerlink" title="dataset用法"></a>dataset用法</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">dataset_transform = torchvision.transforms.Compose([</span><br><span class="line">    torchvision.transforms.ToTensor()</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">train_set = torchvision.datasets.CIFAR10(root=<span class="string">&#x27;./dayo2/dataset&#x27;</span>,train=<span class="literal">True</span>,transform=dataset_transform,download=<span class="literal">True</span>)</span><br><span class="line">//train 是指算不算训练集，transform是对这个数据集开始使用的工具</span><br><span class="line"></span><br><span class="line">test_set = torchvision.datasets.CIFAR10(root=<span class="string">&#x27;./dayo2/dataset&#x27;</span>,train=<span class="literal">False</span>,transform=dataset_transform,download=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<h3 id="DataLoader用法"><a href="#DataLoader用法" class="headerlink" title="DataLoader用法"></a>DataLoader用法</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">test_loader = DataLoader(dataset=test_set, batch_size=<span class="number">64</span>, shuffle=<span class="literal">True</span>, drop_last=<span class="literal">False</span>)</span><br><span class="line">//参数分别是之前的数据集，batch_size是一次性取出来的数目，shuffle是指是否两次之间要打乱抽取，drop_last为<span class="literal">False</span>指最后不足<span class="number">64</span>的要不要舍弃</span><br><span class="line">writer = SummaryWriter(<span class="string">&quot;day03_log&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>):</span><br><span class="line">    step=<span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> test_loader:</span><br><span class="line">        img,target = data</span><br><span class="line">        writer.add_images(<span class="string">&quot;epoch:&#123;&#125;&quot;</span>.<span class="built_in">format</span>(epoch),img,global_step=step)</span><br><span class="line">        step +=<span class="number">1</span></span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure>

<p><img src="https://cdn.jsdelivr.net/gh/thanyi/image/20210914093625.png"></p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">ethanyi</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://thanyi.github.io/2021/08/06/013NLP%E5%AD%A6%E4%B9%A0_pytorch/">https://thanyi.github.io/2021/08/06/013NLP%E5%AD%A6%E4%B9%A0_pytorch/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://thanyi.github.io" target="_blank">Ethanyi's Blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></div><div class="post_share"><div class="social-share" data-image="https://cdn.jsdelivr.net/gh/thanyi/image/20210814164731.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button button--animated"><i class="fas fa-qrcode"></i> 打赏</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="/img/wechat.png" target="_blank"><img class="post-qr-code-img" src="/img/wechat.png" alt="微信"/></a><div class="post-qr-code-desc">微信</div></li><li class="reward-item"><a href="/img/alipay.jpg" target="_blank"><img class="post-qr-code-img" src="/img/alipay.jpg" alt="支付宝"/></a><div class="post-qr-code-desc">支付宝</div></li></ul></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2021/08/07/014ctf%E5%9F%BA%E7%A1%80%E9%A2%9802/"><img class="prev-cover" src="https://cdn.jsdelivr.net/gh/thanyi/image/20210804220352.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">ctf基础题02</div></div></a></div><div class="next-post pull-right"><a href="/2021/07/11/012%E5%85%B3%E4%BA%8E%E5%AE%9E%E8%AE%AD%E4%B8%AD%E7%9A%84%E4%B8%80%E4%BA%9B%E7%9F%A5%E8%AF%86/"><img class="next-cover" src="https://cdn.jsdelivr.net/gh/thanyi/image/20210804220352.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">关于实训中的一些小知识</div></div></a></div></nav><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%A6%82%E5%BF%B5"><span class="toc-number">1.</span> <span class="toc-text">深度学习的概念</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%AD%A6%E4%B9%A0pytorch"><span class="toc-number">2.</span> <span class="toc-text">学习pytorch</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%89%B9%E7%82%B9"><span class="toc-number">2.1.</span> <span class="toc-text">特点</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8pytorch%E8%BF%9B%E8%A1%8C%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%AD%A5%E9%AA%A4"><span class="toc-number">2.2.</span> <span class="toc-text">使用pytorch进行深度学习的步骤</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9E%84%E5%BB%BA%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B"><span class="toc-number">2.2.1.</span> <span class="toc-text">构建神经网络模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BB%BA%E7%AB%8B%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E5%92%8C%E4%BC%98%E5%8C%96%E5%99%A8"><span class="toc-number">2.2.2.</span> <span class="toc-text">建立损失函数和优化器</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="toc-number">2.2.2.1.</span> <span class="toc-text">损失函数</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BC%98%E5%8C%96%E5%99%A8"><span class="toc-number">2.2.2.2.</span> <span class="toc-text">优化器</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AF%B9%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%BF%9B%E8%A1%8C%E5%88%86%E6%89%B9%E6%AC%A1%E8%AE%AD%E7%BB%83"><span class="toc-number">2.2.3.</span> <span class="toc-text">对神经网络进行分批次训练</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E9%A2%84%E5%A4%84%E7%90%86"><span class="toc-number">3.</span> <span class="toc-text">预处理</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86"><span class="toc-number">3.1.</span> <span class="toc-text">数据预处理</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%A2%84%E5%A4%84%E7%90%86%E6%89%8B%E6%AE%B5"><span class="toc-number">3.2.</span> <span class="toc-text">预处理手段</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%AE%9E%E4%BE%8B%EF%BC%9A%E5%85%B3%E4%BA%8E%E5%88%86%E7%B1%BB%E7%9B%B8%E5%85%B3%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0"><span class="toc-number">4.</span> <span class="toc-text">实例：关于分类相关的深度学习</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%96%87%E6%9C%AC%E5%90%91%E9%87%8F%E5%8C%96"><span class="toc-number">4.1.</span> <span class="toc-text">文本向量化</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9E%84%E9%80%A0%E5%88%86%E7%B1%BB%E5%99%A8"><span class="toc-number">4.2.</span> <span class="toc-text">构造分类器</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#pytorch%E7%9A%84%E5%B7%A5%E5%85%B7"><span class="toc-number">5.</span> <span class="toc-text">pytorch的工具</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#TensorBoard%E7%9A%84%E4%BD%BF%E7%94%A8"><span class="toc-number">5.1.</span> <span class="toc-text">TensorBoard的使用</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AF%AD%E6%B3%95"><span class="toc-number">5.1.1.</span> <span class="toc-text">语法</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#transform%E4%BD%BF%E7%94%A8"><span class="toc-number">5.2.</span> <span class="toc-text">transform使用</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%94%A8%E6%B3%95%EF%BC%88%E4%BB%A5totensor-%E4%B8%BA%E4%BE%8B%EF%BC%89"><span class="toc-number">5.2.1.</span> <span class="toc-text">用法（以totensor()为例）</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#pytorch%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9A%84%E8%AF%BB%E5%8F%96"><span class="toc-number">6.</span> <span class="toc-text">pytorch数据集的读取</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#torchvision%E4%B8%AD%E7%9A%84datasets%E5%92%8CDataLoader"><span class="toc-number">6.1.</span> <span class="toc-text">torchvision中的datasets和DataLoader</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#dataset%E7%94%A8%E6%B3%95"><span class="toc-number">6.1.1.</span> <span class="toc-text">dataset用法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#DataLoader%E7%94%A8%E6%B3%95"><span class="toc-number">6.1.2.</span> <span class="toc-text">DataLoader用法</span></a></li></ol></li></ol></li></ol></div></div></div></div></main><footer id="footer" style="background-image: url('https://cdn.jsdelivr.net/gh/thanyi/image/20210814164731.png')"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2023 By ethanyi</div><div class="framework-info"><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly"><img src="https://img.shields.io/badge/Powered-Hexo-blue" data-ll-status="loading"/></a><a target="_blank" rel="noopener" href="https://butterfly.js.org"> <img src="https://img.shields.io/badge/Theme-Butterfly-6513df" data-ll-status="loading"/></a></div><div class="footer_custom_text">博客小白，多多关照</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"><script>(()=>{
  const $countDom = document.getElementById('twikoo-count')
  const init = () => {
    let initData = {
      el: '#twikoo-wrap',
      envId: 'https://blog.ethanyi.xyz/',
      region: ''
    }

    if (false) {
      const otherData = false
      initData = Object.assign(initData, otherData)
    }
    
    twikoo.init(initData)
  }

  const getCount = () => {
    twikoo.getCommentsCount({
      envId: 'https://blog.ethanyi.xyz/',
      region: '',
      urls: [window.location.pathname],
      includeReply: false
    }).then(function (res) {
      $countDom.innerText = res[0].count
    }).catch(function (err) {
      console.error(err);
    });
  }

  const loadTwikoo = (bool = false) => {
    if (typeof twikoo === 'object') {
      init()
      bool && $countDom && setTimeout(getCount,0)
    } else {
      getScript('https://cdn.staticfile.org/twikoo/1.6.4/twikoo.all.min.js').then(()=> {
        init()
        bool && $countDom && setTimeout(getCount,0)
      })
    }
  }

  if ('Twikoo' === 'Twikoo' || !false) {
    if (false) btf.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else loadTwikoo(true)
  } else {
    window.loadOtherComment = () => {
      loadTwikoo()
    }
  }
})()</script></div><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-nest.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>